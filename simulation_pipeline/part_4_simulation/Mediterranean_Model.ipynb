{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d43d87f",
   "metadata": {},
   "source": [
    "# <center> Mediterranean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "952f74cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded successfully!\n",
      "NumPy version: 2.2.6\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "print(\"Imports loaded successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7l5khr78juf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GLOBAL VARIABLES CONFIGURED\n",
      "======================================================================\n",
      "Interval size: 0.041666666666666664 days (1.0 hours)\n",
      "\n",
      "Ship speeds (km/h):\n",
      "  Tanker: 25 km/h (600 km/day)\n",
      "  Bulk Carrier: 28 km/h (672 km/day)\n",
      "  Cargo Ship: 32 km/h (768 km/day)\n",
      "\n",
      "Port loading times (days):\n",
      "  Tanker: 1.04 days\n",
      "  Bulk Carrier: 2.13 days\n",
      "  Cargo Ship: 0.71 days\n",
      "\n",
      "Port unloading times (days):\n",
      "  Tanker: 1.04 days\n",
      "  Bulk Carrier: 2.13 days\n",
      "  Cargo Ship: 0.71 days\n",
      "\n",
      "Port capacity parameters:\n",
      "  Target ρ (utilization): 0.8\n",
      "  Minimum capacity: 1 berth(s)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# GLOBAL VARIABLES - ADJUST THESE TO CONFIGURE THE SIMULATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Simulation time parameters\n",
    "INTERVAL_SIZE = 1/24  # Days per interval (1 hour)\n",
    "\n",
    "# Ship-type-specific speeds (km/h)\n",
    "SHIP_SPEEDS = {\n",
    "    'tanker': 25,        # Tankers typically slower due to size/weight\n",
    "    'bulk carrier': 28,  # Bulk carriers moderate speed\n",
    "    'cargo ship': 32     # Container/cargo ships fastest\n",
    "}\n",
    "\n",
    "# Ship-type-specific port processing times (days)\n",
    "PORT_LOADING_TIMES = {\n",
    "    'tanker': 1.04,       # Tankers take longer to load (liquid cargo)\n",
    "    'bulk carrier': 2.13, # Bulk carriers (based on UNCTAD)\n",
    "    'cargo ship': 0.71    # Cargo ships faster loading (containerized)\n",
    "}\n",
    "\n",
    "PORT_UNLOADING_TIMES = {\n",
    "    'tanker': 1.04,       # Tankers take longer to unload (liquid cargo)\n",
    "    'bulk carrier': 2.13, # Bulk carriers moderate unloading time\n",
    "    'cargo ship': 0.71   # Cargo ships faster unloading (containerized)\n",
    "}\n",
    "\n",
    "# Port capacity parameters (queuing theory)\n",
    "TARGET_RHO = 0.8  # Target utilization factor (λ / (c × μ) < ρ)\n",
    "                  # Lower values = less congestion, higher capacities\n",
    "                  # Typical range: 0.7-0.9\n",
    "MIN_PORT_CAPACITY = 1  # Minimum berths per port\n",
    "\n",
    "# Data directories\n",
    "NETWORK_DIR = '../part_3_network_extraction/network_outputs/'\n",
    "SHIP_DATA_FILE = 'simulation_output_data/simulation_ship_data.csv'\n",
    "OUTPUT_DIR = 'simulation_output_data/'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GLOBAL VARIABLES CONFIGURED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Interval size: {INTERVAL_SIZE} days ({INTERVAL_SIZE * 24:.1f} hours)\")\n",
    "print(f\"\\nShip speeds (km/h):\")\n",
    "for ship_type, speed in SHIP_SPEEDS.items():\n",
    "    print(f\"  {ship_type.title()}: {speed} km/h ({speed * 24} km/day)\")\n",
    "print(f\"\\nPort loading times (days):\")\n",
    "for ship_type, time in PORT_LOADING_TIMES.items():\n",
    "    print(f\"  {ship_type.title()}: {time} days\")\n",
    "print(f\"\\nPort unloading times (days):\")\n",
    "for ship_type, time in PORT_UNLOADING_TIMES.items():\n",
    "    print(f\"  {ship_type.title()}: {time} days\")\n",
    "print(f\"\\nPort capacity parameters:\")\n",
    "print(f\"  Target ρ (utilization): {TARGET_RHO}\")\n",
    "print(f\"  Minimum capacity: {MIN_PORT_CAPACITY} berth(s)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89317b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network loaded: 328 nodes, 526 edges\n",
      "  Ports: 42\n",
      "  Choke points: 1\n",
      "  Network nodes: 285\n",
      "\n",
      "Port-Country Mappings:\n",
      "  Unique ports: 42\n",
      "  Unique countries: 22\n",
      "\n",
      "Sample mappings:\n",
      "  Tarragona → Spain\n",
      "  Trieste → Italy\n",
      "  Taranto → Italy\n",
      "  Illichivsk → Ukraine\n",
      "  Larnaca → Cyprus\n",
      "\n",
      "Ports by country:\n",
      "  Albania: 1 ports\n",
      "  Algeria: 2 ports\n",
      "  Bosnia And Herzegovina: 1 ports\n",
      "  Croatia: 2 ports\n",
      "  Cyprus: 1 ports\n",
      "  Egypt: 3 ports\n",
      "  France: 1 ports\n",
      "  Greece: 1 ports\n",
      "  Israel: 1 ports\n",
      "  Italy: 12 ports\n"
     ]
    }
   ],
   "source": [
    "# Load the Contraction Hierarchies network\n",
    "with open(f'{NETWORK_DIR}network_contraction_hierarchies.gpickle', 'rb') as f:\n",
    "    G_ch = pickle.load(f)\n",
    "\n",
    "print(f\"Network loaded: {G_ch.number_of_nodes()} nodes, {G_ch.number_of_edges()} edges\")\n",
    "\n",
    "# Print node type breakdown\n",
    "port_count = sum(1 for n in G_ch.nodes() if G_ch.nodes[n].get('source') == 'port')\n",
    "choke_count = sum(1 for n in G_ch.nodes() if G_ch.nodes[n].get('source') == 'choke_point')\n",
    "network_count = sum(1 for n in G_ch.nodes() if G_ch.nodes[n].get('source') not in ['port', 'choke_point'])\n",
    "\n",
    "print(f\"  Ports: {port_count}\")\n",
    "print(f\"  Choke points: {choke_count}\")\n",
    "print(f\"  Network nodes: {network_count}\")\n",
    "\n",
    "# Create port-country and country-port mappings\n",
    "port_to_country = {}\n",
    "country_to_ports = {}\n",
    "\n",
    "for node in G_ch.nodes():\n",
    "    if G_ch.nodes[node].get('source') == 'port':\n",
    "        port_name = G_ch.nodes[node].get('portName')\n",
    "        country = G_ch.nodes[node].get('country')\n",
    "        \n",
    "        if port_name and country:\n",
    "            # Port to country mapping\n",
    "            port_to_country[port_name] = country\n",
    "            \n",
    "            # Country to ports mapping\n",
    "            if country not in country_to_ports:\n",
    "                country_to_ports[country] = []\n",
    "            country_to_ports[country].append(port_name)\n",
    "\n",
    "print(f\"\\nPort-Country Mappings:\")\n",
    "print(f\"  Unique ports: {len(port_to_country)}\")\n",
    "print(f\"  Unique countries: {len(country_to_ports)}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample mappings:\")\n",
    "for port, country in list(port_to_country.items())[:5]:\n",
    "    print(f\"  {port} → {country}\")\n",
    "\n",
    "print(f\"\\nPorts by country:\")\n",
    "for country in sorted(country_to_ports.keys())[:10]:\n",
    "    print(f\"  {country}: {len(country_to_ports[country])} ports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "nge1b32ib8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking edge attributes...\n",
      "\n",
      "Sample edge: 24 -> 2554\n",
      "Edge attributes: dict_keys(['distance', 'source', 'length'])\n",
      "\n",
      "All edges have 'length' attribute: True\n",
      "Length statistics:\n",
      "  Min: 6.83 km\n",
      "  Max: 555.10 km\n",
      "  Mean: 85.19 km\n",
      "  Total network length: 44809.36 km\n"
     ]
    }
   ],
   "source": [
    "# Check if edges have 'length' parameter\n",
    "print(\"Checking edge attributes...\")\n",
    "sample_edge = list(G_ch.edges(data=True))[0]\n",
    "print(f\"\\nSample edge: {sample_edge[0]} -> {sample_edge[1]}\")\n",
    "print(f\"Edge attributes: {sample_edge[2].keys()}\")\n",
    "\n",
    "# Check if 'length' exists\n",
    "has_length = all('length' in G_ch[u][v] for u, v in G_ch.edges())\n",
    "print(f\"\\nAll edges have 'length' attribute: {has_length}\")\n",
    "\n",
    "if has_length:\n",
    "    lengths = [G_ch[u][v]['length'] for u, v in G_ch.edges()]\n",
    "    print(f\"Length statistics:\")\n",
    "    print(f\"  Min: {min(lengths):.2f} km\")\n",
    "    print(f\"  Max: {max(lengths):.2f} km\")\n",
    "    print(f\"  Mean: {np.mean(lengths):.2f} km\")\n",
    "    print(f\"  Total network length: {sum(lengths):.2f} km\")\n",
    "else:\n",
    "    print(\"WARNING: Not all edges have 'length' attribute!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "qls7c3smkrn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING SHIP DATA FROM ship_generation.ipynb OUTPUT\n",
      "======================================================================\n",
      "\n",
      "✓ Loaded 6964 ships from simulation_output_data/simulation_ship_data.csv\n",
      "  Columns: 198\n",
      "  Memory: 11918.4 KB\n",
      "\n",
      "HS Codes in data: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97]\n",
      "\n",
      "✓ Ship type data found:\n",
      "  Tanker: 3399 ships (48.8%)\n",
      "  Bulk Carrier: 2119 ships (30.4%)\n",
      "  Cargo Ship: 1446 ships (20.8%)\n",
      "\n",
      "Ship cargo statistics:\n",
      "  Total weight: 412,156,884 metric tons\n",
      "  Total value: $651,216,077,865\n",
      "  Mean weight: 59,184 tons\n",
      "  Mean value: $93,511,786\n",
      "  Weight std: 21,221 tons\n",
      "  Value std: $260,490,857\n",
      "\n",
      "Countries in ship data: 20\n",
      "  ['Albania', 'Algeria', 'Croatia', 'Cyprus', 'Egypt', 'France', 'Greece', 'Israel', 'Italy', 'Lebanon', 'Libya', 'Malta', 'Montenegro', 'Morocco', 'Romania', 'Russian Federation', 'Slovenia', 'Spain', 'Tunisia', 'Ukraine']\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# LOAD SHIP DATA FROM CSV\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING SHIP DATA FROM ship_generation.ipynb OUTPUT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the ship data CSV generated by ship_generation.ipynb\n",
    "ship_df = pd.read_csv(SHIP_DATA_FILE)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(ship_df)} ships from {SHIP_DATA_FILE}\")\n",
    "print(f\"  Columns: {len(ship_df.columns)}\")\n",
    "print(f\"  Memory: {ship_df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "# Load HS codes mapping from JSON\n",
    "with open('../../data/hs_codes_mapping.json', 'r') as f:\n",
    "    hs_codes_mapping_full = json.load(f)\n",
    "\n",
    "# Extract HS codes from ship_df columns\n",
    "hs_codes_in_data = []\n",
    "for col in ship_df.columns:\n",
    "    if col.startswith('cargo_hs') and col.endswith('_weight'):\n",
    "        hs_code = int(col.replace('cargo_hs', '').replace('_weight', ''))\n",
    "        hs_codes_in_data.append(hs_code)\n",
    "\n",
    "# Build HS_CODES dictionary with names from JSON\n",
    "HS_CODES = {}\n",
    "for hs_code in sorted(hs_codes_in_data):\n",
    "    hs_str = str(hs_code).zfill(2)\n",
    "    if hs_str in hs_codes_mapping_full:\n",
    "        HS_CODES[hs_code] = hs_codes_mapping_full[hs_str]['name']\n",
    "    else:\n",
    "        HS_CODES[hs_code] = f\"HS{hs_code:02d}\" \n",
    "\n",
    "print(f\"\\nHS Codes in data: {list(HS_CODES.keys())}\")\n",
    "\n",
    "# Check if ship_type column exists\n",
    "if 'ship_type' in ship_df.columns:\n",
    "    print(f\"\\n✓ Ship type data found:\")\n",
    "    ship_type_counts = ship_df['ship_type'].value_counts()\n",
    "    for ship_type, count in ship_type_counts.items():\n",
    "        print(f\"  {ship_type.title()}: {count} ships ({count/len(ship_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Warning: ship_type column not found - using default speed for all ships\")\n",
    "\n",
    "# Display statistics\n",
    "print(f\"\\nShip cargo statistics:\")\n",
    "print(f\"  Total weight: {ship_df['cargo_total_weight'].sum():,.0f} metric tons\")\n",
    "print(f\"  Total value: ${ship_df['cargo_total_value'].sum():,.0f}\")\n",
    "print(f\"  Mean weight: {ship_df['cargo_total_weight'].mean():,.0f} tons\")\n",
    "print(f\"  Mean value: ${ship_df['cargo_total_value'].mean():,.0f}\")\n",
    "print(f\"  Weight std: {ship_df['cargo_total_weight'].std():,.0f} tons\")\n",
    "print(f\"  Value std: ${ship_df['cargo_total_value'].std():,.0f}\")\n",
    "\n",
    "# Get list of countries from ship data\n",
    "countries_in_ships = sorted(set(ship_df['origin_country'].unique()) | set(ship_df['dest_country'].unique()))\n",
    "print(f\"\\nCountries in ship data: {len(countries_in_ships)}\")\n",
    "print(f\"  {countries_in_ships}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "hoodb6s03r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPUTING ROUTES FOR COUNTRY PAIRS\n",
      "======================================================================\n",
      "\n",
      "Found 230 unique country pairs in ship data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing routes: 100%|██████████| 230/230 [00:00<00:00, 1046.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Computed routes for 230 country pairs\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# COMPUTE ROUTES FOR SHIP COUNTRIES\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"COMPUTING ROUTES FOR COUNTRY PAIRS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create port name to node mapping\n",
    "port_name_to_node = {}\n",
    "for node in G_ch.nodes():\n",
    "    if G_ch.nodes[node].get('source') == 'port':\n",
    "        port_name = G_ch.nodes[node].get('portName')\n",
    "        if port_name:\n",
    "            port_name_to_node[port_name] = node\n",
    "\n",
    "# Get unique country pairs from ship data\n",
    "unique_pairs = set(zip(ship_df['origin_country'], ship_df['dest_country']))\n",
    "print(f\"\\nFound {len(unique_pairs)} unique country pairs in ship data\")\n",
    "\n",
    "# Compute routes\n",
    "country_pair_routes = {}\n",
    "\n",
    "for origin_country, dest_country in tqdm(unique_pairs, desc=\"Computing routes\"):\n",
    "    origin_ports = country_to_ports.get(origin_country, [])\n",
    "    dest_ports = country_to_ports.get(dest_country, [])\n",
    "    \n",
    "    if not origin_ports or not dest_ports:\n",
    "        continue\n",
    "    \n",
    "    best_path = None\n",
    "    best_length = float('inf')\n",
    "    best_origin_port = None\n",
    "    best_dest_port = None\n",
    "    \n",
    "    # Try all port combinations\n",
    "    for o_port in origin_ports:\n",
    "        for d_port in dest_ports:\n",
    "            o_node = port_name_to_node.get(o_port)\n",
    "            d_node = port_name_to_node.get(d_port)\n",
    "            \n",
    "            if o_node is None or d_node is None:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                path = nx.shortest_path(G_ch, o_node, d_node, weight='length')\n",
    "                path_length = sum(G_ch[path[i]][path[i+1]].get('length', 0) \n",
    "                                for i in range(len(path)-1))\n",
    "                \n",
    "                if path_length < best_length:\n",
    "                    best_length = path_length\n",
    "                    best_path = path\n",
    "                    best_origin_port = o_port\n",
    "                    best_dest_port = d_port\n",
    "            except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
    "                continue\n",
    "    \n",
    "    if best_path:\n",
    "        country_pair_routes[(origin_country, dest_country)] = {\n",
    "            'path': best_path,\n",
    "            'length': best_length,\n",
    "            'origin_port': best_origin_port,\n",
    "            'dest_port': best_dest_port\n",
    "        }\n",
    "\n",
    "print(f\"\\n✓ Computed routes for {len(country_pair_routes)} country pairs\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca9b1mbn9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RECONSTRUCTING SHIP OBJECTS WITH SHIP-TYPE-SPECIFIC PARAMETERS\n",
      "======================================================================\n",
      "Port processing scaling factors by ship type:\n",
      "  Tanker:\n",
      "    Loading scale: 39.7056\n",
      "    Unloading scale: 39.7056\n",
      "  Bulk Carrier:\n",
      "    Loading scale: 64.3402\n",
      "    Unloading scale: 64.3402\n",
      "  Cargo Ship:\n",
      "    Loading scale: 27.3347\n",
      "    Unloading scale: 27.3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstructing ships: 100%|██████████| 6964/6964 [00:01<00:00, 3851.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Reconstructed 6964 ships\n",
      "\n",
      "Verification:\n",
      "  Total cargo weight: 412,156,884 tons\n",
      "  Total cargo value: $651,216,077,865\n",
      "\n",
      "Port processing times by ship type:\n",
      "  Tanker (3399 ships):\n",
      "    Mean loading: 1.04 days (target: 1.04)\n",
      "    Mean unloading: 1.04 days (target: 1.04)\n",
      "  Bulk Carrier (2119 ships):\n",
      "    Mean loading: 2.12 days (target: 2.13)\n",
      "    Mean unloading: 2.13 days (target: 2.13)\n",
      "  Cargo Ship (1446 ships):\n",
      "    Mean loading: 0.71 days (target: 0.71)\n",
      "    Mean unloading: 0.71 days (target: 0.71)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# RECONSTRUCT SHIP OBJECTS WITH ROUTES AND TIMING\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"RECONSTRUCTING SHIP OBJECTS WITH SHIP-TYPE-SPECIFIC PARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate average ship weights for scaling\n",
    "AVERAGE_SHIP_LOAD_WEIGHT = ship_df['cargo_total_weight'].mean()\n",
    "\n",
    "# Calculate port processing time scaling factors for each ship type\n",
    "scaling_factors = {}\n",
    "\n",
    "for ship_type in ['tanker', 'bulk carrier', 'cargo ship']:\n",
    "    # Get ships of this type\n",
    "    type_mask = ship_df['ship_type'] == ship_type if 'ship_type' in ship_df.columns else ship_df.index.isin([])\n",
    "    \n",
    "    if type_mask.sum() > 0:\n",
    "        type_weights = ship_df.loc[type_mask, 'cargo_total_weight']\n",
    "        log_ratios = [np.log(1 + weight / AVERAGE_SHIP_LOAD_WEIGHT) for weight in type_weights]\n",
    "        mean_log_ratio = np.mean(log_ratios)\n",
    "        \n",
    "        target_loading_intervals = PORT_LOADING_TIMES[ship_type] / INTERVAL_SIZE\n",
    "        target_unloading_intervals = PORT_UNLOADING_TIMES[ship_type] / INTERVAL_SIZE\n",
    "        \n",
    "        loading_scale = target_loading_intervals / mean_log_ratio if mean_log_ratio > 0 else target_loading_intervals\n",
    "        unloading_scale = target_unloading_intervals / mean_log_ratio if mean_log_ratio > 0 else target_unloading_intervals\n",
    "    else:\n",
    "        # Fallback if ship type not found\n",
    "        loading_scale = PORT_LOADING_TIMES[ship_type] / INTERVAL_SIZE\n",
    "        unloading_scale = PORT_UNLOADING_TIMES[ship_type] / INTERVAL_SIZE\n",
    "    \n",
    "    scaling_factors[ship_type] = {\n",
    "        'loading_scale': loading_scale,\n",
    "        'unloading_scale': unloading_scale\n",
    "    }\n",
    "\n",
    "print(f\"Port processing scaling factors by ship type:\")\n",
    "for ship_type, factors in scaling_factors.items():\n",
    "    print(f\"  {ship_type.title()}:\")\n",
    "    print(f\"    Loading scale: {factors['loading_scale']:.4f}\")\n",
    "    print(f\"    Unloading scale: {factors['unloading_scale']:.4f}\")\n",
    "\n",
    "# Reconstruct ships with routes and timing\n",
    "ships = []\n",
    "skipped = 0\n",
    "\n",
    "for idx, row in tqdm(ship_df.iterrows(), total=len(ship_df), desc=\"Reconstructing ships\"):\n",
    "    origin_country = row['origin_country']\n",
    "    dest_country = row['dest_country']\n",
    "    \n",
    "    # Get route\n",
    "    if (origin_country, dest_country) not in country_pair_routes:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    route_info = country_pair_routes[(origin_country, dest_country)]\n",
    "    \n",
    "    # Get ship type\n",
    "    ship_type = row.get('ship_type', 'cargo ship')  # Default to cargo ship if not specified\n",
    "    \n",
    "    # Calculate loading/unloading times (WEIGHT-BASED, ship-type-specific)\n",
    "    ship_weight = row['cargo_total_weight']\n",
    "    log_ratio = np.log(1 + ship_weight / AVERAGE_SHIP_LOAD_WEIGHT)\n",
    "    \n",
    "    loading_mean = max(0.5, log_ratio * scaling_factors[ship_type]['loading_scale'])\n",
    "    unloading_mean = max(0.5, log_ratio * scaling_factors[ship_type]['unloading_scale'])\n",
    "    \n",
    "    loading_intervals = max(1, np.random.poisson(loading_mean))\n",
    "    unloading_intervals = max(1, np.random.poisson(unloading_mean))\n",
    "    \n",
    "    # Build ship dictionary\n",
    "    ship = {\n",
    "        'id': int(row['ship_id']),\n",
    "        'origin_country': origin_country,\n",
    "        'dest_country': dest_country,\n",
    "        'origin_port': route_info['origin_port'],\n",
    "        'dest_port': route_info['dest_port'],\n",
    "        'ship_type': ship_type,  # ADD: ship type\n",
    "        'path': route_info['path'],\n",
    "        'path_length': route_info['length'],\n",
    "        'cargo_total_weight': float(row['cargo_total_weight']),\n",
    "        'cargo_total_value': float(row['cargo_total_value']),\n",
    "        'loading_time': loading_intervals,\n",
    "        'unloading_time': unloading_intervals,\n",
    "        'loading_remaining': loading_intervals,\n",
    "        'unloading_remaining': 0,\n",
    "        'state': 'waiting_to_load',\n",
    "        'current_edge_idx': 0,\n",
    "        'km_into_current_edge': 0.0,\n",
    "        'wait_intervals': 0,\n",
    "        'completed': False\n",
    "    }\n",
    "    \n",
    "    # Add HS code cargo fields\n",
    "    for hs_code in HS_CODES.keys():\n",
    "        ship[f'cargo_hs{hs_code}_weight'] = float(row[f'cargo_hs{hs_code}_weight'])\n",
    "        ship[f'cargo_hs{hs_code}_value'] = float(row[f'cargo_hs{hs_code}_value'])\n",
    "    \n",
    "    ships.append(ship)\n",
    "\n",
    "print(f\"\\n✓ Reconstructed {len(ships)} ships\")\n",
    "if skipped > 0:\n",
    "    print(f\"  ⚠ Skipped {skipped} ships (no route found)\")\n",
    "\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"  Total cargo weight: {sum(s['cargo_total_weight'] for s in ships):,.0f} tons\")\n",
    "print(f\"  Total cargo value: ${sum(s['cargo_total_value'] for s in ships):,.0f}\")\n",
    "\n",
    "# Show loading/unloading times by ship type\n",
    "print(f\"\\nPort processing times by ship type:\")\n",
    "for ship_type in ['tanker', 'bulk carrier', 'cargo ship']:\n",
    "    type_ships = [s for s in ships if s['ship_type'] == ship_type]\n",
    "    if type_ships:\n",
    "        mean_loading = np.mean([s['loading_time'] * INTERVAL_SIZE for s in type_ships])\n",
    "        mean_unloading = np.mean([s['unloading_time'] * INTERVAL_SIZE for s in type_ships])\n",
    "        print(f\"  {ship_type.title()} ({len(type_ships)} ships):\")\n",
    "        print(f\"    Mean loading: {mean_loading:.2f} days (target: {PORT_LOADING_TIMES[ship_type]})\")\n",
    "        print(f\"    Mean unloading: {mean_unloading:.2f} days (target: {PORT_UNLOADING_TIMES[ship_type]})\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "port_init_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIALIZING SIMULATION STATE\n",
      "======================================================================\n",
      "✓ Initialized 42 ports\n",
      "✓ Initialized tracking dictionaries\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# INITIALIZE SIMULATION STATE\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"INITIALIZING SIMULATION STATE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Port state tracking\n",
    "port_states = {}\n",
    "for node in G_ch.nodes():\n",
    "    if G_ch.nodes[node].get('source') == 'port':\n",
    "        port_name = G_ch.nodes[node].get('portName')\n",
    "        if port_name:\n",
    "            port_states[port_name] = {'loading': [], 'unloading': []}\n",
    "\n",
    "print(f\"✓ Initialized {len(port_states)} ports\")\n",
    "\n",
    "# Port wait statistics\n",
    "port_wait_stats = {}\n",
    "for port_name in port_states.keys():\n",
    "    port_wait_stats[port_name] = {\n",
    "        'total_wait_intervals': 0,\n",
    "        'num_ships_waited': 0\n",
    "    }\n",
    "\n",
    "# Initialize tracking dictionaries\n",
    "ship_edge_history = {}\n",
    "ship_locations = {}\n",
    "port_occupancy_by_timestep = {}\n",
    "\n",
    "print(f\"✓ Initialized tracking dictionaries\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ud0r9udh1m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CALCULATING PORT CAPACITIES (QUEUING THEORY)\n",
      "======================================================================\n",
      "✓ Calculated capacities for 42 ports\n",
      "\n",
      "Port capacity statistics:\n",
      "  Min capacity: 1\n",
      "  Max capacity: 9\n",
      "  Mean capacity: 2.2\n",
      "  Median capacity: 1.0\n",
      "\n",
      "Utilization factor (ρ) statistics:\n",
      "  Target ρ: 0.8\n",
      "  Max ρ: 0.792 (must be < 1)\n",
      "  Mean ρ: 0.349\n",
      "  ✓ All ports have ρ < 1 (stable queuing)\n",
      "\n",
      "Top 5 busiest ports (by total ships):\n",
      "  1. Toulon:\n",
      "     Ships: 2228 (from: 1025, to: 1203)\n",
      "     λ: 6.10 ships/day, μ: 0.857 ships/day/berth\n",
      "     Capacity: 9 berths, ρ: 0.792\n",
      "  2. Barcelona:\n",
      "     Ships: 1777 (from: 828, to: 949)\n",
      "     λ: 4.87 ships/day, μ: 0.786 ships/day/berth\n",
      "     Capacity: 8 berths, ρ: 0.774\n",
      "  3. Genova:\n",
      "     Ships: 1546 (from: 461, to: 1085)\n",
      "     λ: 4.24 ships/day, μ: 0.943 ships/day/berth\n",
      "     Capacity: 6 berths, ρ: 0.748\n",
      "  4. Alger:\n",
      "     Ships: 851 (from: 771, to: 80)\n",
      "     λ: 2.33 ships/day, μ: 0.866 ships/day/berth\n",
      "     Capacity: 4 berths, ρ: 0.673\n",
      "  5. Novorossiysk:\n",
      "     Ships: 661 (from: 636, to: 25)\n",
      "     λ: 1.81 ships/day, μ: 0.680 ships/day/berth\n",
      "     Capacity: 4 berths, ρ: 0.666\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CALCULATE PORT CAPACITIES USING QUEUING THEORY\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CALCULATING PORT CAPACITIES (QUEUING THEORY)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "port_capacities = {}\n",
    "port_statistics = {}\n",
    "\n",
    "for port_name in port_states.keys():\n",
    "    # Count ships using this port (both origin and destination)\n",
    "    ships_from_port = sum(1 for s in ships if s['origin_port'] == port_name)\n",
    "    ships_to_port = sum(1 for s in ships if s['dest_port'] == port_name)\n",
    "    total_ships = ships_from_port + ships_to_port\n",
    "    \n",
    "    # Calculate arrival rate λ (ships per day)\n",
    "    lambda_rate = total_ships / 365\n",
    "    \n",
    "    # Calculate average service time (weighted by ship types and operations)\n",
    "    total_service_time = 0\n",
    "    for s in ships:\n",
    "        if s['origin_port'] == port_name:\n",
    "            # Ships departing from this port need loading time\n",
    "            total_service_time += s['loading_time'] * INTERVAL_SIZE\n",
    "        if s['dest_port'] == port_name:\n",
    "            # Ships arriving at this port need unloading time\n",
    "            total_service_time += s['unloading_time'] * INTERVAL_SIZE\n",
    "    \n",
    "    avg_service_time = total_service_time / total_ships if total_ships > 0 else 1.0\n",
    "    \n",
    "    # Calculate service rate μ (ships per day per berth)\n",
    "    mu_rate = 1 / avg_service_time if avg_service_time > 0 else 1.0\n",
    "    \n",
    "    # Calculate minimum capacity for target ρ\n",
    "    # ρ = λ / (c × μ) < TARGET_RHO\n",
    "    # c = λ / (μ × TARGET_RHO)\n",
    "    c_min = lambda_rate / mu_rate / TARGET_RHO\n",
    "    capacity = max(MIN_PORT_CAPACITY, int(np.ceil(c_min)))\n",
    "    \n",
    "    # Verify ρ < 1\n",
    "    actual_rho = lambda_rate / (capacity * mu_rate) if capacity > 0 else 0\n",
    "    \n",
    "    port_capacities[port_name] = capacity\n",
    "    port_statistics[port_name] = {\n",
    "        'ships_from': ships_from_port,\n",
    "        'ships_to': ships_to_port,\n",
    "        'total_ships': total_ships,\n",
    "        'lambda': lambda_rate,\n",
    "        'avg_service_time': avg_service_time,\n",
    "        'mu': mu_rate,\n",
    "        'capacity': capacity,\n",
    "        'rho': actual_rho\n",
    "    }\n",
    "\n",
    "print(f\"✓ Calculated capacities for {len(port_capacities)} ports\")\n",
    "print(f\"\\nPort capacity statistics:\")\n",
    "print(f\"  Min capacity: {min(port_capacities.values())}\")\n",
    "print(f\"  Max capacity: {max(port_capacities.values())}\")\n",
    "print(f\"  Mean capacity: {np.mean(list(port_capacities.values())):.1f}\")\n",
    "print(f\"  Median capacity: {np.median(list(port_capacities.values())):.1f}\")\n",
    "\n",
    "# Verify all ρ < 1\n",
    "max_rho = max(s['rho'] for s in port_statistics.values())\n",
    "print(f\"\\nUtilization factor (ρ) statistics:\")\n",
    "print(f\"  Target ρ: {TARGET_RHO}\")\n",
    "print(f\"  Max ρ: {max_rho:.3f} (must be < 1)\")\n",
    "print(f\"  Mean ρ: {np.mean([s['rho'] for s in port_statistics.values()]):.3f}\")\n",
    "if max_rho >= 1:\n",
    "    print(f\"  ⚠ WARNING: Some ports have ρ ≥ 1! System unstable!\")\n",
    "else:\n",
    "    print(f\"  ✓ All ports have ρ < 1 (stable queuing)\")\n",
    "\n",
    "# Show top 5 busiest ports\n",
    "print(f\"\\nTop 5 busiest ports (by total ships):\")\n",
    "sorted_ports = sorted(port_statistics.items(), key=lambda x: x[1]['total_ships'], reverse=True)[:5]\n",
    "for i, (port_name, stats) in enumerate(sorted_ports, 1):\n",
    "    print(f\"  {i}. {port_name}:\")\n",
    "    print(f\"     Ships: {stats['total_ships']} (from: {stats['ships_from']}, to: {stats['ships_to']})\")\n",
    "    print(f\"     λ: {stats['lambda']:.2f} ships/day, μ: {stats['mu']:.3f} ships/day/berth\")\n",
    "    print(f\"     Capacity: {stats['capacity']} berths, ρ: {stats['rho']:.3f}\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "gkldm75mfrr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Mediterranean shipping simulation with WEIGHT AND VALUE tracking...\n",
      "Simulating 365 days with 0.041666666666666664-day intervals\n",
      "VERSION 3: Weight-based simulation with value tracking\n",
      "======================================================================\n",
      "Initialized edge_traffic with 526 network edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating days: 100%|██████████| 8760/8760 [00:18<00:00, 472.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SIMULATION COMPLETE!\n",
      "======================================================================\n",
      "Total edges: 526 (network: 526)\n",
      "Ship-edge traversals: 88778\n",
      "Ships completed: 6934\n",
      "Timesteps: 8760\n",
      "\n",
      "Edge coverage:\n",
      "  With traffic: 340\n",
      "  Without traffic: 186\n",
      "\n",
      "Traffic by commodity (WEIGHT in metric tons):\n",
      "  HS01 (Live animals): 7,538,889 tons\n",
      "  HS02 (Meat and edible meat offal): 17,226,994 tons\n",
      "  HS03 (Fish and crustaceans, molluscs and other aquatic invertebrates): 7,409,316 tons\n",
      "  HS04 (Dairy produce; birds eggs; natural honey; edible products of animal origin): 14,202,282 tons\n",
      "  HS05 (Products of animal origin, not elsewhere specified or included): 1,591,729 tons\n",
      "  HS06 (Live trees and other plants; bulbs, roots and the like; cut flowers): 1,289,202 tons\n",
      "  HS07 (Edible vegetables and certain roots and tubers): 73,698,757 tons\n",
      "  HS08 (Edible fruit and nuts; peel of citrus fruit or melons): 51,433,599 tons\n",
      "  HS09 (Coffee, tea, mate and spices): 3,975,316 tons\n",
      "  HS10 (Cereals): 1,577,457,076 tons\n",
      "  HS11 (Products of the milling industry; malt; starches; inulin; wheat gluten): 7,873,328 tons\n",
      "  HS12 (Oil seeds and oleaginous fruits; miscellaneous grains, seeds and fruit): 67,551,180 tons\n",
      "  HS13 (Lac; gums, resins and other vegetable saps and extracts): 65,906 tons\n",
      "  HS14 (Vegetable plaiting materials; vegetable products not elsewhere specified): 936,561 tons\n",
      "  HS15 (Animal or vegetable fats and oils and their cleavage products): 63,797,604 tons\n",
      "  HS16 (Preparations of meat, of fish or of crustaceans, molluscs): 3,742,014 tons\n",
      "  HS17 (Sugars and sugar confectionery): 40,997,212 tons\n",
      "  HS18 (Cocoa and cocoa preparations): 4,211,314 tons\n",
      "  HS19 (Preparations of cereals, flour, starch or milk; pastrycooks products): 12,077,196 tons\n",
      "  HS20 (Preparations of vegetables, fruit, nuts or other parts of plants): 15,975,661 tons\n",
      "  HS21 (Miscellaneous edible preparations): 6,261,230 tons\n",
      "  HS22 (Beverages, spirits and vinegar): 32,901,118 tons\n",
      "  HS23 (Residues and waste from the food industries; prepared animal fodder): 97,146,821 tons\n",
      "  HS24 (Tobacco and manufactured tobacco substitutes): 745,320 tons\n",
      "  HS25 (Salt; sulphur; earths and stone; plastering materials, lime and cement): 257,207,309 tons\n",
      "  HS26 (Ores, slag and ash): 22,800,550 tons\n",
      "  HS27 (Mineral fuels, mineral oils and products of their distillation): 1,830,090,519 tons\n",
      "  HS28 (Inorganic chemicals; organic or inorganic compounds of precious metals): 54,641,888 tons\n",
      "  HS29 (Organic chemicals): 50,853,118 tons\n",
      "  HS30 (Pharmaceutical products): 11,763,781 tons\n",
      "  HS31 (Fertilisers): 154,421,500 tons\n",
      "  HS32 (Tanning or dyeing extracts; tannins and their derivatives; dyes, pigments): 5,752,382 tons\n",
      "  HS33 (Essential oils and resinoids; perfumery, cosmetic or toilet preparations): 8,862,958 tons\n",
      "  HS34 (Soap, organic surface-active agents, washing preparations, lubricants): 16,508,020 tons\n",
      "  HS35 (Albuminoidal substances; modified starches; glues; enzymes): 2,761,832 tons\n",
      "  HS36 (Explosives; pyrotechnic products; matches; pyrophoric alloys): 6,717 tons\n",
      "  HS37 (Photographic or cinematographic goods): 22,638 tons\n",
      "  HS38 (Miscellaneous chemical products): 29,193,552 tons\n",
      "  HS39 (Plastics and articles thereof): 83,804,273 tons\n",
      "  HS40 (Rubber and articles thereof): 10,169,209 tons\n",
      "  HS41 (Raw hides and skins (other than furskins) and leather): 1,715,106 tons\n",
      "  HS42 (Articles of leather; saddlery and harness; travel goods, handbags): 708,466 tons\n",
      "  HS43 (Furskins and artificial fur; manufactures thereof): 0 tons\n",
      "  HS44 (Wood and articles of wood; wood charcoal): 82,399,248 tons\n",
      "  HS45 (Cork and articles of cork): 771,057 tons\n",
      "  HS46 (Manufactures of straw, of esparto or of other plaiting materials): 48,245 tons\n",
      "  HS47 (Pulp of wood or of other fibrous cellulosic material; recovered paper): 17,740,805 tons\n",
      "  HS48 (Paper and paperboard; articles of paper pulp, of paper or of paperboard): 46,421,480 tons\n",
      "  HS49 (Printed books, newspapers, pictures and other products of the printing industry): 2,590,216 tons\n",
      "  HS50 (Silk): 9,516 tons\n",
      "  HS51 (Wool, fine or coarse animal hair; horsehair yarn and woven fabric): 59,202 tons\n",
      "  HS52 (Cotton): 2,406,762 tons\n",
      "  HS53 (Other vegetable textile fibres; paper yarn and woven fabrics): 233,418 tons\n",
      "  HS54 (Man-made filaments; strip and the like of man-made textile materials): 1,469,217 tons\n",
      "  HS55 (Man-made staple fibres): 565,608 tons\n",
      "  HS56 (Wadding, felt and nonwovens; special yarns; twine, cordage, ropes): 3,382,960 tons\n",
      "  HS57 (Carpets and other textile floor coverings): 756,294 tons\n",
      "  HS58 (Special woven fabrics; tufted textile fabrics; lace; tapestries): 29,503 tons\n",
      "  HS59 (Impregnated, coated, covered or laminated textile fabrics): 614,079 tons\n",
      "  HS60 (Knitted or crocheted fabrics): 547,512 tons\n",
      "  HS61 (Articles of apparel and clothing accessories, knitted or crocheted): 1,660,069 tons\n",
      "  HS62 (Articles of apparel and clothing accessories, not knitted or crocheted): 2,836,076 tons\n",
      "  HS63 (Other made up textile articles; sets; worn clothing and worn textile): 2,380,602 tons\n",
      "  HS64 (Footwear, gaiters and the like; parts of such articles): 1,120,016 tons\n",
      "  HS65 (Headgear and parts thereof): 32,079 tons\n",
      "  HS66 (Umbrellas, sun umbrellas, walking-sticks, seat-sticks, whips): 0 tons\n",
      "  HS67 (Prepared feathers and down and articles made of feathers or of down): 0 tons\n",
      "  HS68 (Articles of stone, plaster, cement, asbestos, mica or similar materials): 25,915,581 tons\n",
      "  HS69 (Ceramic products): 47,936,895 tons\n",
      "  HS70 (Glass and glassware): 24,087,556 tons\n",
      "  HS71 (Natural or cultured pearls, precious or semi-precious stones, precious metals): 4,441 tons\n",
      "  HS72 (Iron and steel): 268,215,480 tons\n",
      "  HS73 (Articles of iron or steel): 40,723,626 tons\n",
      "  HS74 (Copper and articles thereof): 9,433,060 tons\n",
      "  HS75 (Nickel and articles thereof): 19,266 tons\n",
      "  HS76 (Aluminium and articles thereof): 23,354,762 tons\n",
      "  HS78 (Lead and articles thereof): 1,961,324 tons\n",
      "  HS79 (Zinc and articles thereof): 1,141,484 tons\n",
      "  HS80 (Tin and articles thereof): 160,605 tons\n",
      "  HS81 (Other base metals; cermets; articles thereof): 11,962 tons\n",
      "  HS82 (Tools, implements, cutlery, spoons and forks, of base metal): 138,356 tons\n",
      "  HS83 (Miscellaneous articles of base metal): 3,823,402 tons\n",
      "  HS84 (Machinery and mechanical appliances; parts thereof): 38,578,534 tons\n",
      "  HS85 (Electrical machinery and equipment and parts thereof): 24,463,642 tons\n",
      "  HS86 (Railway or tramway locomotives, rolling-stock and parts thereof): 4,010,315 tons\n",
      "  HS87 (Vehicles other than railway or tramway rolling-stock, and parts): 66,716,400 tons\n",
      "  HS88 (Aircraft, spacecraft, and parts thereof): 294,305 tons\n",
      "  HS89 (Ships, boats and floating structures): 2,878,155 tons\n",
      "  HS90 (Optical, photographic, cinematographic, measuring, checking, precision instruments): 3,545,273 tons\n",
      "  HS91 (Clocks and watches and parts thereof): 58 tons\n",
      "  HS92 (Musical instruments; parts and accessories of such articles): 0 tons\n",
      "  HS93 (Arms and ammunition; parts and accessories thereof): 267,063 tons\n",
      "  HS94 (Furniture; bedding, mattresses, mattress supports, cushions): 11,497,125 tons\n",
      "  HS95 (Toys, games and sports requisites; parts and accessories thereof): 1,857,329 tons\n",
      "  HS96 (Miscellaneous manufactured articles): 1,122,205 tons\n",
      "  HS97 (Works of art, collectors pieces and antiques): 0 tons\n",
      "\n",
      "Traffic by commodity (VALUE in USD):\n",
      "  HS01 (Live animals): $29,202,710,352\n",
      "  HS02 (Meat and edible meat offal): $71,424,934,018\n",
      "  HS03 (Fish and crustaceans, molluscs and other aquatic invertebrates): $45,452,143,066\n",
      "  HS04 (Dairy produce; birds eggs; natural honey; edible products of animal origin): $49,092,067,850\n",
      "  HS05 (Products of animal origin, not elsewhere specified or included): $3,229,780,513\n",
      "  HS06 (Live trees and other plants; bulbs, roots and the like; cut flowers): $5,550,238,658\n",
      "  HS07 (Edible vegetables and certain roots and tubers): $63,781,406,407\n",
      "  HS08 (Edible fruit and nuts; peel of citrus fruit or melons): $75,429,907,427\n",
      "  HS09 (Coffee, tea, mate and spices): $19,707,919,431\n",
      "  HS10 (Cereals): $419,294,411,068\n",
      "  HS11 (Products of the milling industry; malt; starches; inulin; wheat gluten): $5,888,500,016\n",
      "  HS12 (Oil seeds and oleaginous fruits; miscellaneous grains, seeds and fruit): $80,869,710,990\n",
      "  HS13 (Lac; gums, resins and other vegetable saps and extracts): $1,254,974,807\n",
      "  HS14 (Vegetable plaiting materials; vegetable products not elsewhere specified): $239,316,600\n",
      "  HS15 (Animal or vegetable fats and oils and their cleavage products): $90,752,233,813\n",
      "  HS16 (Preparations of meat, of fish or of crustaceans, molluscs): $19,302,721,295\n",
      "  HS17 (Sugars and sugar confectionery): $36,486,875,900\n",
      "  HS18 (Cocoa and cocoa preparations): $24,207,366,797\n",
      "  HS19 (Preparations of cereals, flour, starch or milk; pastrycooks products): $34,907,827,258\n",
      "  HS20 (Preparations of vegetables, fruit, nuts or other parts of plants): $29,246,359,422\n",
      "  HS21 (Miscellaneous edible preparations): $30,179,648,981\n",
      "  HS22 (Beverages, spirits and vinegar): $52,273,748,130\n",
      "  HS23 (Residues and waste from the food industries; prepared animal fodder): $49,812,866,061\n",
      "  HS24 (Tobacco and manufactured tobacco substitutes): $17,829,803,512\n",
      "  HS25 (Salt; sulphur; earths and stone; plastering materials, lime and cement): $28,348,848,519\n",
      "  HS26 (Ores, slag and ash): $2,809,729,970\n",
      "  HS27 (Mineral fuels, mineral oils and products of their distillation): $1,220,256,391,798\n",
      "  HS28 (Inorganic chemicals; organic or inorganic compounds of precious metals): $43,355,111,926\n",
      "  HS29 (Organic chemicals): $80,981,498,123\n",
      "  HS30 (Pharmaceutical products): $597,618,773,708\n",
      "  HS31 (Fertilisers): $75,031,687,293\n",
      "  HS32 (Tanning or dyeing extracts; tannins and their derivatives; dyes, pigments): $16,280,822,330\n",
      "  HS33 (Essential oils and resinoids; perfumery, cosmetic or toilet preparations): $100,598,331,092\n",
      "  HS34 (Soap, organic surface-active agents, washing preparations, lubricants): $29,921,065,395\n",
      "  HS35 (Albuminoidal substances; modified starches; glues; enzymes): $13,387,461,614\n",
      "  HS36 (Explosives; pyrotechnic products; matches; pyrophoric alloys): $10,569,485\n",
      "  HS37 (Photographic or cinematographic goods): $119,665,241\n",
      "  HS38 (Miscellaneous chemical products): $90,374,870,888\n",
      "  HS39 (Plastics and articles thereof): $244,097,277,446\n",
      "  HS40 (Rubber and articles thereof): $46,879,194,771\n",
      "  HS41 (Raw hides and skins (other than furskins) and leather): $9,173,263,386\n",
      "  HS42 (Articles of leather; saddlery and harness; travel goods, handbags): $56,570,759,710\n",
      "  HS43 (Furskins and artificial fur; manufactures thereof): $0\n",
      "  HS44 (Wood and articles of wood; wood charcoal): $62,340,202,296\n",
      "  HS45 (Cork and articles of cork): $1,960,546,541\n",
      "  HS46 (Manufactures of straw, of esparto or of other plaiting materials): $354,292,027\n",
      "  HS47 (Pulp of wood or of other fibrous cellulosic material; recovered paper): $8,813,432,599\n",
      "  HS48 (Paper and paperboard; articles of paper pulp, of paper or of paperboard): $79,858,411,628\n",
      "  HS49 (Printed books, newspapers, pictures and other products of the printing industry): $14,180,701,064\n",
      "  HS50 (Silk): $1,087,656,557\n",
      "  HS51 (Wool, fine or coarse animal hair; horsehair yarn and woven fabric): $2,014,642,968\n",
      "  HS52 (Cotton): $10,526,555,944\n",
      "  HS53 (Other vegetable textile fibres; paper yarn and woven fabrics): $1,658,898,408\n",
      "  HS54 (Man-made filaments; strip and the like of man-made textile materials): $13,127,640,511\n",
      "  HS55 (Man-made staple fibres): $2,670,574,009\n",
      "  HS56 (Wadding, felt and nonwovens; special yarns; twine, cordage, ropes): $15,525,756,691\n",
      "  HS57 (Carpets and other textile floor coverings): $2,038,577,493\n",
      "  HS58 (Special woven fabrics; tufted textile fabrics; lace; tapestries): $657,017,612\n",
      "  HS59 (Impregnated, coated, covered or laminated textile fabrics): $8,380,160,322\n",
      "  HS60 (Knitted or crocheted fabrics): $9,293,110,058\n",
      "  HS61 (Articles of apparel and clothing accessories, knitted or crocheted): $55,824,415,657\n",
      "  HS62 (Articles of apparel and clothing accessories, not knitted or crocheted): $126,929,983,383\n",
      "  HS63 (Other made up textile articles; sets; worn clothing and worn textile): $28,022,139,464\n",
      "  HS64 (Footwear, gaiters and the like; parts of such articles): $55,903,843,136\n",
      "  HS65 (Headgear and parts thereof): $2,057,948,684\n",
      "  HS66 (Umbrellas, sun umbrellas, walking-sticks, seat-sticks, whips): $62\n",
      "  HS67 (Prepared feathers and down and articles made of feathers or of down): $0\n",
      "  HS68 (Articles of stone, plaster, cement, asbestos, mica or similar materials): $20,581,700,788\n",
      "  HS69 (Ceramic products): $36,426,876,842\n",
      "  HS70 (Glass and glassware): $37,602,766,109\n",
      "  HS71 (Natural or cultured pearls, precious or semi-precious stones, precious metals): $3,958,176,005\n",
      "  HS72 (Iron and steel): $196,111,084,904\n",
      "  HS73 (Articles of iron or steel): $127,926,348,734\n",
      "  HS74 (Copper and articles thereof): $92,576,755,376\n",
      "  HS75 (Nickel and articles thereof): $723,714,474\n",
      "  HS76 (Aluminium and articles thereof): $89,710,170,438\n",
      "  HS78 (Lead and articles thereof): $4,181,865,791\n",
      "  HS79 (Zinc and articles thereof): $3,875,669,657\n",
      "  HS80 (Tin and articles thereof): $3,744,178,983\n",
      "  HS81 (Other base metals; cermets; articles thereof): $173,441,127\n",
      "  HS82 (Tools, implements, cutlery, spoons and forks, of base metal): $2,253,851,493\n",
      "  HS83 (Miscellaneous articles of base metal): $50,949,043,107\n",
      "  HS84 (Machinery and mechanical appliances; parts thereof): $578,805,514,892\n",
      "  HS85 (Electrical machinery and equipment and parts thereof): $618,679,841,065\n",
      "  HS86 (Railway or tramway locomotives, rolling-stock and parts thereof): $15,716,747,497\n",
      "  HS87 (Vehicles other than railway or tramway rolling-stock, and parts): $719,573,850,112\n",
      "  HS88 (Aircraft, spacecraft, and parts thereof): $24,879,742,463\n",
      "  HS89 (Ships, boats and floating structures): $15,967,368,413\n",
      "  HS90 (Optical, photographic, cinematographic, measuring, checking, precision instruments): $266,060,630,892\n",
      "  HS91 (Clocks and watches and parts thereof): $1,494,776\n",
      "  HS92 (Musical instruments; parts and accessories of such articles): $85\n",
      "  HS93 (Arms and ammunition; parts and accessories thereof): $2,439,847,937\n",
      "  HS94 (Furniture; bedding, mattresses, mattress supports, cushions): $71,287,019,491\n",
      "  HS95 (Toys, games and sports requisites; parts and accessories thereof): $20,226,630,925\n",
      "  HS96 (Miscellaneous manufactured articles): $12,400,798,078\n",
      "  HS97 (Works of art, collectors pieces and antiques): $0\n",
      "\n",
      "Time statistics:\n",
      "  Total ship-hours: 294,493 hours\n",
      "  Total ship-days: 12,271 days\n",
      "  Avg per traversal: 3.32 hours\n",
      "\n",
      "Port processing:\n",
      "  Avg loading: 1.30 days\n",
      "  Avg unloading: 1.30 days\n",
      "\n",
      "Wait statistics:\n",
      "  Total wait: 1101.25 days\n",
      "  Ships waited: 1450\n",
      "  Avg wait: 0.76 days\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# RUN SIMULATION - WEIGHT AND VALUE TRACKING (VERSION 3)\n",
    "# ==============================================================================\n",
    "# This version tracks BOTH weight and value for all cargo\n",
    "print(\"Running Mediterranean shipping simulation with WEIGHT AND VALUE tracking...\")\n",
    "print(f\"Simulating 365 days with {INTERVAL_SIZE}-day intervals\")\n",
    "print(\"VERSION 3: Weight-based simulation with value tracking\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Helper function to normalize edge keys\n",
    "def normalize_edge_key(node1, node2):\n",
    "    \"\"\"Return canonical edge key for undirected graphs\"\"\"\n",
    "    try:\n",
    "        if node1 < node2:\n",
    "            return (node1, node2)\n",
    "        else:\n",
    "            return (node2, node1)\n",
    "    except TypeError:\n",
    "        if str(node1) < str(node2):\n",
    "            return (node1, node2)\n",
    "        else:\n",
    "            return (node2, node1)\n",
    "\n",
    "# Initialize edge traffic data structure with WEIGHT AND VALUE fields\n",
    "def create_edge_traffic_entry():\n",
    "    \"\"\"Create edge traffic entry with weight and value fields for each HS code\"\"\"\n",
    "    entry = {\n",
    "        'ship_count': 0,\n",
    "        'origin_dest_pairs': {},\n",
    "        'cargo_total_weight': 0.0,  # NEW: total weight\n",
    "        'cargo_total_value': 0.0,   # NEW: total value\n",
    "        'total_time_hours': 0.0\n",
    "    }\n",
    "    # Add weight and value fields for each HS code\n",
    "    for hs_code in HS_CODES.keys():\n",
    "        entry[f'cargo_hs{hs_code}_weight'] = 0.0\n",
    "        entry[f'cargo_hs{hs_code}_value'] = 0.0\n",
    "    return entry\n",
    "\n",
    "def create_od_pair_entry():\n",
    "    \"\"\"Create OD pair entry with weight and value fields\"\"\"\n",
    "    entry = {\n",
    "        'count': 0,\n",
    "        'cargo_total_weight': 0.0,\n",
    "        'cargo_total_value': 0.0\n",
    "    }\n",
    "    # Add weight and value fields for each HS code\n",
    "    for hs_code in HS_CODES.keys():\n",
    "        entry[f'cargo_hs{hs_code}_weight'] = 0.0\n",
    "        entry[f'cargo_hs{hs_code}_value'] = 0.0\n",
    "    return entry\n",
    "\n",
    "# Initialize ALL network edges\n",
    "edge_traffic = {}\n",
    "for node1, node2 in G_ch.edges():\n",
    "    edge_key = normalize_edge_key(node1, node2)\n",
    "    if edge_key not in edge_traffic:\n",
    "        edge_traffic[edge_key] = create_edge_traffic_entry()\n",
    "\n",
    "print(f\"Initialized edge_traffic with {len(edge_traffic)} network edges\")\n",
    "\n",
    "# Parameters\n",
    "lambda_param = len(ships) * INTERVAL_SIZE / 365\n",
    "hours_per_interval = INTERVAL_SIZE * 24\n",
    "\n",
    "# Simulation state\n",
    "simulation_steps = []\n",
    "n_intervals = int(365 / INTERVAL_SIZE)\n",
    "\n",
    "# Statistics\n",
    "total_loading_intervals = 0\n",
    "total_unloading_intervals = 0\n",
    "num_ships_completed = 0\n",
    "cargo_additions = 0\n",
    "\n",
    "# Track total cargo transported (not per-edge, just per-ship)\n",
    "total_cargo_weight_transported = 0\n",
    "total_cargo_value_transported = 0\n",
    "\n",
    "# Main simulation loop\n",
    "for interval in tqdm(range(n_intervals), desc=\"Simulating days\"):\n",
    "    day = interval * INTERVAL_SIZE\n",
    "    n_new_ships = np.random.poisson(lambda_param)\n",
    "\n",
    "    # Add new ships\n",
    "    ships_to_add = []\n",
    "    for _ in range(n_new_ships):\n",
    "        if ships:\n",
    "            new_ship = ships.pop(0)\n",
    "            ships_to_add.append(new_ship)\n",
    "\n",
    "    if interval == 0:\n",
    "        active_ships = ships_to_add\n",
    "    else:\n",
    "        active_ships.extend(ships_to_add)\n",
    "\n",
    "    current_locations = {}\n",
    "\n",
    "    # === PHASE 1: Port operations ===\n",
    "    for ship in active_ships:\n",
    "        if ship['state'] == 'waiting_to_load':\n",
    "            port = ship['origin_port']\n",
    "            if len(port_states[port]['loading']) < port_capacities[port]:\n",
    "                port_states[port]['loading'].append(ship['id'])\n",
    "                ship['state'] = 'loading'\n",
    "            else:\n",
    "                ship['wait_intervals'] += 1\n",
    "\n",
    "        elif ship['state'] == 'loading':\n",
    "            ship['loading_remaining'] -= 1\n",
    "            if ship['loading_remaining'] <= 0:\n",
    "                port = ship['origin_port']\n",
    "                port_states[port]['loading'].remove(ship['id'])\n",
    "                ship['state'] = 'traveling'\n",
    "                total_loading_intervals += ship['loading_time']\n",
    "\n",
    "        elif ship['state'] == 'waiting_to_unload':\n",
    "            port = ship['dest_port']\n",
    "            if len(port_states[port]['unloading']) < port_capacities[port]:\n",
    "                port_states[port]['unloading'].append(ship['id'])\n",
    "                ship['state'] = 'unloading'\n",
    "                ship['unloading_remaining'] = ship['unloading_time']\n",
    "            else:\n",
    "                ship['wait_intervals'] += 1\n",
    "\n",
    "        elif ship['state'] == 'unloading':\n",
    "            ship['unloading_remaining'] -= 1\n",
    "            if ship['unloading_remaining'] <= 0:\n",
    "                port = ship['dest_port']\n",
    "                port_states[port]['unloading'].remove(ship['id'])\n",
    "                ship['state'] = 'completed'\n",
    "                ship['completed'] = True\n",
    "                total_cargo_weight_transported += ship[\"cargo_total_weight\"]\n",
    "                total_cargo_value_transported += ship[\"cargo_total_value\"]\n",
    "                total_unloading_intervals += ship['unloading_time']\n",
    "                num_ships_completed += 1\n",
    "\n",
    "    # Record port locations\n",
    "    for ship in active_ships:\n",
    "        if ship['state'] in ['waiting_to_load', 'loading']:\n",
    "            current_locations[ship['id']] = {\n",
    "                'status': 'loading',\n",
    "                'port': ship['origin_port']\n",
    "            }\n",
    "        elif ship['state'] in ['waiting_to_unload', 'unloading']:\n",
    "            current_locations[ship['id']] = {\n",
    "                'status': 'unloading',\n",
    "                'port': ship['dest_port']\n",
    "            }\n",
    "\n",
    "    # === PHASE 2: Move traveling ships ===\n",
    "    ships_to_remove = []\n",
    "\n",
    "    for ship in active_ships:\n",
    "        if ship['state'] != 'traveling':\n",
    "            continue\n",
    "\n",
    "        if ship['completed']:\n",
    "            ships_to_remove.append(ship)\n",
    "            continue\n",
    "\n",
    "        km_remaining = SHIP_SPEEDS[ship['ship_type']] * 24 * INTERVAL_SIZE\n",
    "        edge_time_allocation = {}\n",
    "\n",
    "        while km_remaining > 0 and ship['state'] == 'traveling':\n",
    "            edge_idx = ship['current_edge_idx']\n",
    "            if edge_idx >= len(ship['path']) - 1:\n",
    "                ship['state'] = 'waiting_to_unload'\n",
    "                current_locations[ship['id']] = {\n",
    "                    'status': 'arrived',\n",
    "                    'port': ship['dest_port']\n",
    "                }\n",
    "                break\n",
    "\n",
    "            node1 = ship['path'][edge_idx]\n",
    "            node2 = ship['path'][edge_idx + 1]\n",
    "\n",
    "            # Get edge length\n",
    "            if G_ch.has_edge(node1, node2):\n",
    "                edge_length = G_ch[node1][node2].get('length', 0)\n",
    "            elif G_ch.has_edge(node2, node1):\n",
    "                edge_length = G_ch[node2][node1].get('length', 0)\n",
    "            else:\n",
    "                edge_length = 0\n",
    "\n",
    "            km_left_in_edge = edge_length - ship['km_into_current_edge']\n",
    "            edge_key = normalize_edge_key(node1, node2)\n",
    "            ship_id_int = ship['id']\n",
    "\n",
    "            if ship_id_int not in ship_edge_history:\n",
    "                ship_edge_history[ship_id_int] = set()\n",
    "\n",
    "            # CARGO ATTRIBUTION: Add weight and value when ship enters edge\n",
    "            if edge_key not in ship_edge_history[ship_id_int]:\n",
    "                ship_edge_history[ship_id_int].add(edge_key)\n",
    "\n",
    "                if edge_key not in edge_traffic:\n",
    "                    edge_traffic[edge_key] = create_edge_traffic_entry()\n",
    "\n",
    "                edge_traffic[edge_key]['ship_count'] += 1\n",
    "                edge_traffic[edge_key]['cargo_total_weight'] += ship['cargo_total_weight']\n",
    "                edge_traffic[edge_key]['cargo_total_value'] += ship['cargo_total_value']\n",
    "\n",
    "                # Add weight and value for each HS code\n",
    "                for hs_code in HS_CODES.keys():\n",
    "                    weight_field = f'cargo_hs{hs_code}_weight'\n",
    "                    value_field = f'cargo_hs{hs_code}_value'\n",
    "                    edge_traffic[edge_key][weight_field] += ship.get(weight_field, 0.0)\n",
    "                    edge_traffic[edge_key][value_field] += ship.get(value_field, 0.0)\n",
    "\n",
    "                # Track OD pairs\n",
    "                od_key = (ship['origin_country'], ship['dest_country'])\n",
    "                if od_key not in edge_traffic[edge_key]['origin_dest_pairs']:\n",
    "                    edge_traffic[edge_key]['origin_dest_pairs'][od_key] = create_od_pair_entry()\n",
    "\n",
    "                edge_traffic[edge_key]['origin_dest_pairs'][od_key]['count'] += 1\n",
    "                edge_traffic[edge_key]['origin_dest_pairs'][od_key]['cargo_total_weight'] += ship['cargo_total_weight']\n",
    "                edge_traffic[edge_key]['origin_dest_pairs'][od_key]['cargo_total_value'] += ship['cargo_total_value']\n",
    "\n",
    "                # Add OD weight and value for each HS code\n",
    "                for hs_code in HS_CODES.keys():\n",
    "                    weight_field = f'cargo_hs{hs_code}_weight'\n",
    "                    value_field = f'cargo_hs{hs_code}_value'\n",
    "                    edge_traffic[edge_key]['origin_dest_pairs'][od_key][weight_field] += ship.get(weight_field, 0.0)\n",
    "                    edge_traffic[edge_key]['origin_dest_pairs'][od_key][value_field] += ship.get(value_field, 0.0)\n",
    "\n",
    "                cargo_additions += 1\n",
    "\n",
    "            if km_remaining >= km_left_in_edge:\n",
    "                # Complete edge\n",
    "                km_traveled = km_left_in_edge\n",
    "                hours_for_segment = (km_traveled / SHIP_SPEEDS[ship['ship_type']]) if SHIP_SPEEDS[ship['ship_type']] > 0 else 0\n",
    "\n",
    "                if edge_key not in edge_time_allocation:\n",
    "                    edge_time_allocation[edge_key] = 0.0\n",
    "                edge_time_allocation[edge_key] += hours_for_segment\n",
    "\n",
    "                km_remaining -= km_left_in_edge\n",
    "                ship['current_edge_idx'] += 1\n",
    "                ship['km_into_current_edge'] = 0.0\n",
    "            else:\n",
    "                # Partial edge\n",
    "                km_traveled = km_remaining\n",
    "                hours_for_segment = (km_traveled / SHIP_SPEEDS[ship['ship_type']]) if SHIP_SPEEDS[ship['ship_type']] > 0 else 0\n",
    "\n",
    "                if edge_key not in edge_time_allocation:\n",
    "                    edge_time_allocation[edge_key] = 0.0\n",
    "                edge_time_allocation[edge_key] += hours_for_segment\n",
    "\n",
    "                ship['km_into_current_edge'] += km_remaining\n",
    "\n",
    "                current_locations[ship['id']] = {\n",
    "                    'status': 'active',\n",
    "                    'edge': [str(node1), str(node2)],\n",
    "                    'edge_length_km': float(edge_length),\n",
    "                    'progress_km': float(ship['km_into_current_edge']),\n",
    "                    'progress_fraction': float(ship['km_into_current_edge'] / edge_length) if edge_length > 0 else 0.0\n",
    "                }\n",
    "\n",
    "                km_remaining = 0\n",
    "\n",
    "        # Add time to edges\n",
    "        for edge_key, hours_spent in edge_time_allocation.items():\n",
    "            if edge_key in edge_traffic:\n",
    "                edge_traffic[edge_key]['total_time_hours'] += hours_spent\n",
    "\n",
    "    # Remove completed ships\n",
    "    for ship in ships_to_remove:\n",
    "        active_ships.remove(ship)\n",
    "\n",
    "    # Record port occupancy\n",
    "    port_occupancy_by_timestep[interval] = {}\n",
    "    for port_name, state in port_states.items():\n",
    "        num_ships = len(state['loading']) + len(state['unloading'])\n",
    "        if num_ships > 0:\n",
    "            port_occupancy_by_timestep[interval][port_name] = num_ships\n",
    "\n",
    "    # Store locations\n",
    "    if current_locations:\n",
    "        ship_locations[str(day)] = current_locations\n",
    "\n",
    "    simulation_steps.append({\n",
    "        'day': day,\n",
    "        'active_ships': len(active_ships),\n",
    "        'new_ships': n_new_ships,\n",
    "        'completed_ships': len(ships_to_remove)\n",
    "    })\n",
    "\n",
    "# Calculate wait stats\n",
    "for ship in active_ships:\n",
    "    if ship['wait_intervals'] > 0:\n",
    "        if ship['state'] in ['waiting_to_load', 'loading']:\n",
    "            port = ship['origin_port']\n",
    "        else:\n",
    "            port = ship['dest_port']\n",
    "        port_wait_stats[port]['total_wait_intervals'] += ship['wait_intervals']\n",
    "        port_wait_stats[port]['num_ships_waited'] += 1\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"SIMULATION COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total edges: {len(edge_traffic)} (network: {G_ch.number_of_edges()})\")\n",
    "print(f\"Ship-edge traversals: {cargo_additions}\")\n",
    "print(f\"Ships completed: {num_ships_completed}\")\n",
    "print(f\"Timesteps: {len(ship_locations)}\")\n",
    "\n",
    "edges_with_traffic = sum(1 for e in edge_traffic.values() if e['ship_count'] > 0)\n",
    "print(f\"\\nEdge coverage:\")\n",
    "print(f\"  With traffic: {edges_with_traffic}\")\n",
    "print(f\"  Without traffic: {len(edge_traffic) - edges_with_traffic}\")\n",
    "\n",
    "# Show WEIGHT breakdown\n",
    "print(f\"\\nTraffic by commodity (WEIGHT in metric tons):\")\n",
    "for hs_code, description in HS_CODES.items():\n",
    "    weight_field = f'cargo_hs{hs_code}_weight'\n",
    "    total_weight = sum(e[weight_field] for e in edge_traffic.values())\n",
    "    print(f\"  HS{hs_code:02d} ({description}): {total_weight:,.0f} tons\")\n",
    "\n",
    "# Show VALUE breakdown  \n",
    "print(f\"\\nTraffic by commodity (VALUE in USD):\")\n",
    "for hs_code, description in HS_CODES.items():\n",
    "    value_field = f'cargo_hs{hs_code}_value'\n",
    "    total_value = sum(e[value_field] for e in edge_traffic.values())\n",
    "    print(f\"  HS{hs_code:02d} ({description}): ${total_value:,.0f}\")\n",
    "\n",
    "# Time statistics\n",
    "total_time = sum(e['total_time_hours'] for e in edge_traffic.values())\n",
    "print(f\"\\nTime statistics:\")\n",
    "print(f\"  Total ship-hours: {total_time:,.0f} hours\")\n",
    "print(f\"  Total ship-days: {total_time / 24:,.0f} days\")\n",
    "print(f\"  Avg per traversal: {total_time / cargo_additions:.2f} hours\" if cargo_additions > 0 else \"  N/A\")\n",
    "\n",
    "# Port statistics\n",
    "avg_loading = total_loading_intervals * INTERVAL_SIZE / num_ships_completed if num_ships_completed > 0 else 0\n",
    "avg_unloading = total_unloading_intervals * INTERVAL_SIZE / num_ships_completed if num_ships_completed > 0 else 0\n",
    "\n",
    "print(f\"\\nPort processing:\")\n",
    "print(f\"  Avg loading: {avg_loading:.2f} days\")\n",
    "print(f\"  Avg unloading: {avg_unloading:.2f} days\")\n",
    "\n",
    "total_wait = sum(s['total_wait_intervals'] for s in port_wait_stats.values())\n",
    "total_waited = sum(s['num_ships_waited'] for s in port_wait_stats.values())\n",
    "print(f\"\\nWait statistics:\")\n",
    "print(f\"  Total wait: {total_wait * INTERVAL_SIZE:.2f} days\")\n",
    "print(f\"  Ships waited: {total_waited}\")\n",
    "print(f\"  Avg wait: {total_wait / total_waited * INTERVAL_SIZE:.2f} days\" if total_waited > 0 else \"  None\")\n",
    "\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cl04a6u015m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPORTING SIMULATION RESULTS\n",
      "======================================================================\n",
      "\n",
      "1. Exporting ship locations...\n",
      "   ✓ Exported simulation_ship_location.json (8760 timesteps)\n",
      "\n",
      "2. Exporting edge statistics...\n",
      "   ✓ Exported simulation_edge_statistics.csv (526 edges)\n",
      "\n",
      "   Edge statistics:\n",
      "     Edges with traffic: 340\n",
      "     Edges with NO traffic: 186\n",
      "     Total weight: 5,421,621,610 tons\n",
      "     Total value: $7,431,294,432,629\n",
      "\n",
      "3. Exporting port occupancy...\n",
      "   ✓ Exported simulation_port_occupancy.csv (161814 records)\n",
      "\n",
      "======================================================================\n",
      "SIMULATION OUTPUT COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Output files:\n",
      "  1. simulation_ship_data.csv (from ship_generation.ipynb)\n",
      "     - Ship cargo composition with weight and value\n",
      "\n",
      "  2. simulation_ship_location.json\n",
      "     - Ship positions at each timestep\n",
      "\n",
      "  3. simulation_edge_statistics.csv\n",
      "     - ALL 526 network edges with traffic statistics\n",
      "     - Includes BOTH weight (tons) and value (USD)\n",
      "\n",
      "  4. simulation_port_occupancy.csv\n",
      "     - Port occupancy over time\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Next steps:\n",
      "  - Use Video_Simulation.ipynb to create animated videos\n",
      "  - Use Simulation_Visualizations.ipynb for static visualizations\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# EXPORT SIMULATION RESULTS (SHIP LOCATIONS, EDGE STATS, PORT OCCUPANCY)\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"EXPORTING SIMULATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Note: simulation_ship_data.csv is already exported by ship_generation.ipynb\n",
    "# This cell exports the remaining 3 output files\n",
    "\n",
    "# 1. Export simulation_ship_location.json\n",
    "print(f\"\\n1. Exporting ship locations...\")\n",
    "with open('simulation_output_data/simulation_ship_location.json', 'w') as f:\n",
    "    json.dump(ship_locations, f, indent=2)\n",
    "print(f\"   ✓ Exported simulation_ship_location.json ({len(ship_locations)} timesteps)\")\n",
    "\n",
    "# 2. Export simulation_edge_statistics.csv WITH WEIGHT AND VALUE\n",
    "print(f\"\\n2. Exporting edge statistics...\")\n",
    "edge_stats_list = []\n",
    "\n",
    "for edge_key, traffic_data in edge_traffic.items():\n",
    "    node1, node2 = edge_key\n",
    "    \n",
    "    # Get edge length\n",
    "    edge_length = 0\n",
    "    if G_ch.has_edge(node1, node2):\n",
    "        edge_length = G_ch[node1][node2].get('length', 0)\n",
    "    elif G_ch.has_edge(node2, node1):\n",
    "        edge_length = G_ch[node2][node1].get('length', 0)\n",
    "    \n",
    "    edge_stat = {\n",
    "        'node1': str(node1),\n",
    "        'node2': str(node2),\n",
    "        'edge_length_km': float(edge_length),\n",
    "        'ship_count': int(traffic_data['ship_count']),\n",
    "        'total_time_hours': float(traffic_data['total_time_hours']),\n",
    "        'cargo_total_weight': float(traffic_data['cargo_total_weight']),\n",
    "        'cargo_total_value': float(traffic_data['cargo_total_value'])\n",
    "    }\n",
    "    \n",
    "    # Add weight and value for each HS code\n",
    "    for hs_code in HS_CODES.keys():\n",
    "        weight_field = f'cargo_hs{hs_code}_weight'\n",
    "        value_field = f'cargo_hs{hs_code}_value'\n",
    "        edge_stat[weight_field] = float(traffic_data[weight_field])\n",
    "        edge_stat[value_field] = float(traffic_data[value_field])\n",
    "    \n",
    "    edge_stats_list.append(edge_stat)\n",
    "\n",
    "edge_df = pd.DataFrame(edge_stats_list)\n",
    "edge_df.to_csv('simulation_output_data/simulation_edge_statistics.csv', index=False)\n",
    "print(f\"   ✓ Exported simulation_edge_statistics.csv ({len(edge_df)} edges)\")\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\n   Edge statistics:\")\n",
    "print(f\"     Edges with traffic: {(edge_df['ship_count'] > 0).sum()}\")\n",
    "print(f\"     Edges with NO traffic: {(edge_df['ship_count'] == 0).sum()}\")\n",
    "print(f\"     Total weight: {edge_df['cargo_total_weight'].sum():,.0f} tons\")\n",
    "print(f\"     Total value: ${edge_df['cargo_total_value'].sum():,.0f}\")\n",
    "\n",
    "# 3. Export simulation_port_occupancy.csv\n",
    "print(f\"\\n3. Exporting port occupancy...\")\n",
    "port_occupancy_list = []\n",
    "n_intervals = int(365 / INTERVAL_SIZE)\n",
    "\n",
    "for interval in range(n_intervals):\n",
    "    timestep_day = interval * INTERVAL_SIZE\n",
    "    \n",
    "    if interval in port_occupancy_by_timestep:\n",
    "        for port_name, num_ships in port_occupancy_by_timestep[interval].items():\n",
    "            port_occupancy_list.append({\n",
    "                'timestep': interval,\n",
    "                'day': float(timestep_day),\n",
    "                'port_name': port_name,\n",
    "                'num_ships': int(num_ships),\n",
    "                'capacity': int(port_capacities[port_name])\n",
    "            })\n",
    "\n",
    "port_occ_df = pd.DataFrame(port_occupancy_list)\n",
    "port_occ_df.to_csv('simulation_output_data/simulation_port_occupancy.csv', index=False)\n",
    "print(f\"   ✓ Exported simulation_port_occupancy.csv ({len(port_occ_df)} records)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SIMULATION OUTPUT COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  1. simulation_ship_data.csv (from ship_generation.ipynb)\")\n",
    "print(f\"     - Ship cargo composition with weight and value\")\n",
    "print(f\"\")\n",
    "print(f\"  2. simulation_ship_location.json\")\n",
    "print(f\"     - Ship positions at each timestep\")\n",
    "print(f\"\")\n",
    "print(f\"  3. simulation_edge_statistics.csv\")\n",
    "print(f\"     - ALL {len(edge_df)} network edges with traffic statistics\")\n",
    "print(f\"     - Includes BOTH weight (tons) and value (USD)\")\n",
    "print(f\"\")\n",
    "print(f\"  4. simulation_port_occupancy.csv\")\n",
    "print(f\"     - Port occupancy over time\")\n",
    "print(f\"\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  - Use Video_Simulation.ipynb to create animated videos\")\n",
    "print(\"  - Use Simulation_Visualizations.ipynb for static visualizations\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hjnkmxokk9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MEDITERRANEAN SHIPPING SIMULATION - SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Simulation Parameters:\n",
      "  Ships simulated: 6934\n",
      "  Interval size: 0.041666666666666664 days (1.0 hours)\n",
      "  Simulation period: 365 days (1 year)\n",
      "\n",
      "Cargo Statistics:\n",
      "  Total weight transported: 409,964,378 metric tons\n",
      "  Total value transported: $649,968,241,548\n",
      "\n",
      "Network Statistics:\n",
      "  Total network edges: 526\n",
      "  Edges with traffic: 340\n",
      "  Ship-edge traversals: 88778\n",
      "  Timesteps tracked: 8760\n",
      "\n",
      "Top 5 Busiest Edges (by cargo WEIGHT):\n",
      "  1. Node 4927 ↔ Istanbul\n",
      "     Ships: 1,559 | Weight: 100,918,442 tons\n",
      "  2. Node 834 ↔ Node 1662\n",
      "     Ships: 1,558 | Weight: 100,835,290 tons\n",
      "  3. Node 834 ↔ Node 4927\n",
      "     Ships: 1,558 | Weight: 100,835,290 tons\n",
      "  4. Node 1662 ↔ Node 7634\n",
      "     Ships: 1,557 | Weight: 100,782,782 tons\n",
      "  5. Node 3516 ↔ Node 8313\n",
      "     Ships: 1,546 | Weight: 84,665,603 tons\n",
      "\n",
      "Output Files:\n",
      "  ✓ simulation_ship_data.csv (from ship_generation.ipynb)\n",
      "  ✓ simulation_ship_location.json\n",
      "  ✓ simulation_edge_statistics.csv\n",
      "  ✓ simulation_port_occupancy.csv\n",
      "\n",
      "======================================================================\n",
      "WEIGHT-BASED SIMULATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Workflow:\n",
      "  1. ship_generation.ipynb - Generate ships with weight/value data\n",
      "  2. Mediterranean_Model.ipynb - Simulate movement and generate outputs\n",
      "\n",
      "Key Features:\n",
      "  ✓ Weight-based ship sampling and routing\n",
      "  ✓ Port queuing with dynamic capacities (queuing theory)\n",
      "  ✓ Ship-type-specific speeds and processing times\n",
      "  ✓ Both weight (tons) and value (USD) tracked\n",
      "  ✓ Modular design for faster iteration\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SIMULATION SUMMARY\n",
    "# ==============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"MEDITERRANEAN SHIPPING SIMULATION - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nSimulation Parameters:\")\n",
    "print(f\"  Ships simulated: {num_ships_completed}\")\n",
    "print(f\"  Interval size: {INTERVAL_SIZE} days ({INTERVAL_SIZE * 24:.1f} hours)\")\n",
    "print(f\"  Simulation period: 365 days (1 year)\")\n",
    "\n",
    "print(f\"\\nCargo Statistics:\")\n",
    "print(f\"  Total weight transported: {total_cargo_weight_transported:,.0f} metric tons\")\n",
    "print(f\"  Total value transported: ${total_cargo_value_transported:,.0f}\")\n",
    "\n",
    "print(f\"\\nNetwork Statistics:\")\n",
    "print(f\"  Total network edges: {G_ch.number_of_edges()}\")\n",
    "print(f\"  Edges with traffic: {sum(1 for e in edge_traffic.values() if e['ship_count'] > 0)}\")\n",
    "print(f\"  Ship-edge traversals: {sum(e['ship_count'] for e in edge_traffic.values())}\")\n",
    "print(f\"  Timesteps tracked: {len(ship_locations)}\")\n",
    "\n",
    "# Find busiest routes BY WEIGHT\n",
    "print(f\"\\nTop 5 Busiest Edges (by cargo WEIGHT):\")\n",
    "sorted_edges_weight = sorted(edge_traffic.items(), \n",
    "                             key=lambda x: x[1]['cargo_total_weight'], \n",
    "                             reverse=True)[:5]\n",
    "\n",
    "for i, (edge, data) in enumerate(sorted_edges_weight, 1):\n",
    "    node1, node2 = edge\n",
    "    name1 = G_ch.nodes[node1].get('portName', f\"Node {node1}\")\n",
    "    name2 = G_ch.nodes[node2].get('portName', f\"Node {node2}\")\n",
    "    \n",
    "    print(f\"  {i}. {name1} ↔ {name2}\")\n",
    "    print(f\"     Ships: {data['ship_count']:,} | Weight: {data['cargo_total_weight']:,.0f} tons\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  ✓ simulation_ship_data.csv (from ship_generation.ipynb)\")\n",
    "print(f\"  ✓ simulation_ship_location.json\")\n",
    "print(f\"  ✓ simulation_edge_statistics.csv\")\n",
    "print(f\"  ✓ simulation_port_occupancy.csv\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"WEIGHT-BASED SIMULATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nWorkflow:\")\n",
    "print(\"  1. ship_generation.ipynb - Generate ships with weight/value data\")\n",
    "print(\"  2. Mediterranean_Model.ipynb - Simulate movement and generate outputs\")\n",
    "print()\n",
    "print(\"Key Features:\")\n",
    "print(\"  ✓ Weight-based ship sampling and routing\")\n",
    "print(\"  ✓ Port queuing with dynamic capacities (queuing theory)\")\n",
    "print(\"  ✓ Ship-type-specific speeds and processing times\")\n",
    "print(\"  ✓ Both weight (tons) and value (USD) tracked\")\n",
    "print(\"  ✓ Modular design for faster iteration\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
